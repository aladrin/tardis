#!/bin/bash
SCRIPT=${0##*/}

f_usage() {
  echo "usage: $SCRIPT -b bucket [-c client] [-k key] [-m mount [-d level|-r file [-t Standard|Bulk]]] [-q ALL|STANDARD|DEEP_ARCHIVE]"
  echo "options: -r (restore)"
  echo "         -d (dump)"
  echo "         -D (delete)"
  echo "         -q (query)"
  echo "         -t tier Standard (3-5 hours)"
  echo "         -t tier Bulk (5-12 hours)"
}

f_error() {
  echo "$SCRIPT: $1 missing argument"
}

f_check() {
  which $1 2>/dev/null || {
    echo $SCRIPT: $1 not found 1>&2
    exit 1
  }
}

f_depend() {
  mkdir -p /etc/${SCRIPT}.d /var/db/$SCRIPT
  [ -z "$CLIENT" ] && CLIENT=${HOSTNAME%%.*}
  [ -z "$KEY" ] && KEY=/etc/${SCRIPT}.d/${CLIENT}.key
  ### THE LOGIC IN THIS NEEDS SOME WORK
  [ -f $KEY ] || { dd if=/dev/urandom bs=1 count=8192 of=$KEY; chmod 400 $KEY; }
  [ -z "$BUCKET" ] && { f_error -b; f_usage; exit 1; }
}

f_check aws 1>/dev/null && AWS=$(f_check aws)
f_check dump 1>/dev/null && DUMP=$(f_check dump)
f_check openssl 1>/dev/null && OPENSSL=$(f_check openssl)
f_check tqdm 1>/dev/null && TQDM=$(f_check tqdm)
f_check zstd 1>/dev/null && ZSTD=$(f_check zstd)
OS=$(uname -s)
if [ "$OS" = Linux ]; then
  export LD_LIBRARY_PATH=/usr/local/lib
  ENC=-chacha20
  DUMPDATES=/var/lib/dumpdates
  f_check dateutils.dconv 1>/dev/null && DATECONV=$(f_check dateutils.dconv)
  f_check tac 1>/dev/null && TAC=$(f_check tac)
  DEVICE=$(mount|fgrep " $2 "|awk '{print $1}')
elif [ "$OS" = OpenBSD ]; then
  ENC=-chacha
  DUMPDATES=/etc/dumpdates
  f_check dateconv 1>/dev/null && DATECONV=$(f_check dateconv)
  f_check gtac 1>/dev/null && TAC=$(f_check gtac)
  DEVICE=$(mount -v|fgrep " $2 "|awk '{print $2}'|sed -e 's/(//' -e 's/)//')
else
  echo Unsupported OS
  exit 1
fi
# better sort out some proper checking to ensure chacha is supported with the OpenSSL version
#OPENSSL_VERSION="$($OPENSSL version)"
#[ ${OPENSSL_VERSION%% *} = LibreSSL ] || { echo $SCRIPT: LibreSSL not found; exit 1; }
LOG_FILE=/var/log/$SCRIPT
DGST=sha256

f_restore() {
  f_depend
  [ -z "$RESTORE" ] && { f_error -f; f_usage; exit 1; }
  [ -z "$MOUNT" ] && { f_error -m; f_usage; exit 1; }
  [ -z "$TIER" ] && TIER=Bulk
  DATA_FILE=$CLIENT/$RESTORE
  REQUEST=\'{\"Days\":1,\"GlacierJobParameters\":{\"Tier\":\"$TIER\"}}\'
  eval $AWS s3api restore-object \
    --bucket $BUCKET \
    --key $DATA_FILE \
    --restore-request $REQUEST
  QUERY=STANDARD
  while ! f_query|fgrep -q $DATA_FILE; do
    date
    sleep $((60*60))
  done
  f_query|fgrep $DATA_FILE
  TOTAL=$(aws s3 ls s3://$BUCKET/$DATA_FILE|awk '{print $3}')
  cd $MOUNT
  $AWS s3 cp $BUCKET/$DATA_FILE - | \
    $TQDM --bytes --total $TOTAL| \
    $OPENSSL enc $ENC -d -pass file:$KEY | \
    $ZSTD -d --stdout | \
    restore -f - -r $MOUNT 2>/dev/null
}

f_dump() {
  f_depend
  [ -z "$MOUNT" ] && { f_error -m; f_usage; exit 1; }
  [ -z "$DUMP_LEVEL" ] && { f_error -d; f_usage; exit 1; }
  if [ "$OS" = Linux ]; then
    DEVICE=$(mount|fgrep " $MOUNT "|awk '{print $1}')
  elif [ "$OS" = OpenBSD ]; then
    DEVICE=$(mount -v|fgrep " $MOUNT "|awk '{print $2}'|sed -e 's/(//' -e 's/)//')
  fi
  mount|fgrep  -q " $MOUNT " || { echo ${MOUNT}: not mounted; exit 1; }
  FORMAT='%a %b %d %T %Y'
  touch $DUMPDATES
  $TAC $DUMPDATES |
  while read -r LINE; do
    LINE=( $LINE )
    [ "${LINE[0]}" = $DEVICE ] && {
      [ $DUMP_LEVEL -gt ${LINE[1]} ] && {
        touch -t $(echo ${LINE[@]}|awk '{print $3,$4,$5,$6,$7}'|$DATECONV -i "$FORMAT" -f "%Y%m%d%H%M.%S") $RUNFILE
        break
      }
    }
  done
  df $MOUNT &>/dev/null && {
    DATE=$(date +%Y-%m-%d_%H:%M:%S)
    echo $(date): $@>>$LOG_FILE
    BASE_FILE=${DATE}_${CLIENT}$(echo $MOUNT|sed 's/\//_/g')_$DUMP_LEVEL
    DATA_FILE=$BASE_FILE.zst.dat
    DGST_FILE=$BASE_FILE.$DGST
    LIST_FILE=${BASE_FILE}_list.zst.dat
    LOCAL_LIST_FILE=/var/db/$SCRIPT/${BASE_FILE}_list.zst
    [ -t 0 ] && echo -n "Reading inodes on $MOUNT (dump level $DUMP_LEVEL): "
    TOTAL=$(find $MOUNT -xdev -newer $RUNFILE -ls | \
    tee >($ZSTD -22 --ultra --stdout | tee $LOCAL_LIST_FILE  | \
    $OPENSSL enc $ENC -e -pass file:$KEY | \
    $AWS s3 cp - $BUCKET/$LIST_FILE) | \
    awk '{sum+=$7}END{print sum}')
    [ -t 0 ] && echo DONE
    [ -n "$TOTAL" ] || {
      echo "${SCRIPT}: no change for $MOUNT (dump level $DUMP_LEVEL)"
      $AWS s3 rm $BUCKET/$LIST_FILE >/dev/null
      exit
    } && {
      [ -t 0 ] && TQDM="$TQDM --bytes --total $TOTAL" || TQDM=cat
      $DUMP -$1 -u -f - $MOUNT 2>/dev/null | \
      $TQDM | \
      $ZSTD --long --stdout | \
      $OPENSSL enc $ENC -e -pass file:$KEY | \
      tee >($OPENSSL dgst -$DGST | \
      awk -v d=$DGST -v o=$DATA_FILE '{gsub("stdin", o)} {gsub("^", toupper(d))} $1' | \
      $AWS s3 cp - $BUCKET/$DGST_FILE) | \
      $AWS s3 cp --storage-class DEEP_ARCHIVE --expected-size $TOTAL - $BUCKET/$DATA_FILE 2>>$LOG_FILE
    }
  }
}

f_query() {
  f_depend
  [ $QUERY = ALL ] && QUERY="STANDARD DEEP_ARCHIVE"
  for QRY in $QUERY; do
    Q=\"Contents[?StorageClass==\'$QRY\']\"
    eval $AWS s3api list-objects-v2 --bucket $BUCKET --query $Q | fgrep $CLIENT
  done
}

f_delete() {
  [ -z "$DELETE" ] && { f_error -f; f_usage; exit 1; }
  $AWS s3 rm s3://$BUCKET/$CLIENT/$DELETE
}

[ $# = 0 ] && { f_usage; exit 1; }

while getopts "D:b:c:q:r:t:m:d:h" OPT; do
   case $OPT in
    h  ) f_usage;;
    b  ) BUCKET=$OPTARG;;
    c  ) CLIENT=$OPTARG;;
    t  ) TIER=$OPTARG;;
    m  ) MOUNT=$OPTARG;;
    d  ) DUMP_LEVEL=$OPTARG;f_dump;;
    D  ) DELETE=$OPTARG;f_delete;;
    r  ) RESTORE=$OPTARG;f_restore;;
    q  ) QUERY=$OPTARG;f_query;;
    \? ) f_usage;;
  esac 
done
